[MODEL]
source = es
target = en
layers = 2
hidden_size = 300
word_vec_size = 256
attention = general
max_length = 50
bidirectional = True
rnn_dropout = 0.3
attn_dropout = 0.1
input_feed = True
uniform_init = 0.1

[TRAINING]
print_every = 10
steps = 100000
batch_size = 32
optimizer = adam
learning_rate = 0.001
lr_reducing_factor = 0.5
patience = 2
save_every = 0
teacher = True
teacher_ratio = 0.5
valid_steps = 5000